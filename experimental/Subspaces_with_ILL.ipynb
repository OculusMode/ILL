{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Subspaces_with_ILL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOJg35IG5QGvJlnyUMCGgHh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OculusMode/ILL/blob/main/experimental/Subspaces_with_ILL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO:: EQUAL FUNCTION FOR SUBSPACES TO REMOVE REDUNDUNCY\n",
        "\n",
        "# TODO:: VISUALIZE VIA NETWORKX\n",
        "\n"
      ],
      "metadata": {
        "id": "C7TSXFXaNvqx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95X1Jeh0EXpu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numpy import random, linalg as LA\n",
        "from collections import defaultdict, deque\n",
        "import gc\n",
        "import networkx as nx"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N = 10\n",
        "M = 4\n",
        "TOTAL_PARTITIONS = 10"
      ],
      "metadata": {
        "id": "P3ECQgROHLaP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Subspace:\n",
        "  def __init__(self, basis, indices):\n",
        "    self.basis = basis\n",
        "    self.indices = indices\n",
        "\n",
        "class SubspacePartition:\n",
        "  # , N=10\n",
        "  def __init__(self, subspaces):\n",
        "    self.subspaces = subspaces # list of Subspace class\n",
        "    # self.N = N\n",
        "\n",
        "  def __eq__(self, other):\n",
        "    subspaces_1 = self.subspaces\n",
        "    subspaces_2 = other.subspaces\n",
        "    s1 = set([frozenset(subspace.indices) for subspace in subspaces_1])\n",
        "    s2 = set([frozenset(subspace.indices) for subspace in subspaces_2])\n",
        "    return s1 == s2\n",
        "\n",
        "  def __hash__(self):\n",
        "    return hash(frozenset(self.subspaces))\n",
        "\n",
        "  @staticmethod\n",
        "  def to_partn(all_basis, indices):\n",
        "    new_partn = []\n",
        "    indices = [np.array(list(i)) for i in indices]\n",
        "    for basis_idx in indices:\n",
        "      new_partn.append(Subspace(all_basis[basis_idx], basis_idx))\n",
        "    return SubspacePartition(new_partn)\n",
        "\n",
        "  def is_coarser(self, other_partn):\n",
        "    \"\"\"Returns 1 if coarse, -1 if finer, 0 if undecidable\"\"\"\n",
        "    # TODO:: WHAT IF SET OF BASIS ARE TOTALLY DIFFERENT??\n",
        "    basis_1 = [i.indices for i in self.subspaces]\n",
        "    basis_2 = [i.indices for i in other_partn.subspaces]\n",
        "    l_1 = len(basis_1)\n",
        "    l_2 = len(basis_2)\n",
        "    # print(basis_1, basis_2)\n",
        "    # if both lengths are same then they cannot be finer/coarser\n",
        "    if l_1 == l_2:\n",
        "      return 0\n",
        "    # the rule with smaller rule_domain MAY BE coarser\n",
        "    if l_1 > l_2:\n",
        "      for i in basis_1:\n",
        "        for j in basis_2:\n",
        "          if not (set(i).issubset(set(j)) or set(i).isdisjoint(set(j))):\n",
        "            return 0\n",
        "      return -1\n",
        "    else:\n",
        "      for i in basis_2:\n",
        "        for j in basis_1:\n",
        "          if not (set(i).issubset(set(j)) or set(i).isdisjoint(set(j))):\n",
        "            return 0\n",
        "      return 1\n",
        "\n",
        "  def print_partition(self):\n",
        "    for S in self.subspaces:\n",
        "      print(S.basis, S.indices)\n",
        "    \n",
        "  def print_basis_idx(self):\n",
        "    for S in self.subspaces:\n",
        "      print(S.indices, end=' ')\n",
        "    print()\n",
        "  \n",
        "  @staticmethod\n",
        "  def join(p1, p2, all_basis):\n",
        "    # TODO:: WHAT IF SET OF BASIS ARE TOTALLY DIFFERENT??\n",
        "    new_basis = []\n",
        "    basis_1 = [i.indices for i in p1.subspaces]\n",
        "    basis_2 = [i.indices for i in p2.subspaces]\n",
        "    for i in basis_1:\n",
        "      i = set(i)\n",
        "      for j in basis_2:\n",
        "        j = set(j)\n",
        "        intersection = i.intersection(j)\n",
        "        if intersection:\n",
        "          new_basis.append(frozenset(intersection))\n",
        "          j.difference_update(intersection)\n",
        "    r = SubspacePartition.to_partn(all_basis, new_basis)\n",
        "    del new_basis\n",
        "    gc.collect()\n",
        "    return r\n",
        "\n",
        "  @staticmethod\n",
        "  def meet(p1, p2, all_basis):\n",
        "    # TODO:: WHAT IF SET OF BASIS ARE TOTALLY DIFFERENT??\n",
        "    new_basis = [i.indices for i in p1.subspaces]\n",
        "    basis_2 = [i.indices for i in p2.subspaces]\n",
        "    for i in basis_2:\n",
        "      idxs_to_remove = []\n",
        "      temp_set = set(i)\n",
        "      for jindex, j in enumerate(new_basis):\n",
        "        if temp_set.intersection(j):\n",
        "          temp_set.update(j) # taking Union and storing in temp_set\n",
        "          idxs_to_remove.append(jindex)\n",
        "      # now we can remove indexes\n",
        "      # here we are using reversed so we don't mess up by removing smaller indexes first\n",
        "      for i in reversed(idxs_to_remove):\n",
        "        new_basis.pop(i)\n",
        "      new_basis.append(temp_set)\n",
        "    r = SubspacePartition.to_partn(all_basis, new_basis)\n",
        "    del new_basis\n",
        "    gc.collect()\n",
        "    return r\n",
        "\n",
        "\n",
        "def get_random_bases(N):\n",
        "  while True:\n",
        "    random_matrix = np.random.random((N, N))\n",
        "    random_basis, _ = LA.qr(random_matrix)\n",
        "    # making sure we got N basis\n",
        "    if LA.matrix_rank(random_basis) == N:\n",
        "      break\n",
        "  return random_basis\n",
        "\n",
        "def get_random_vector(N, is_normalized = True):\n",
        "  v = random.random(N)\n",
        "  if is_normalized:\n",
        "    return v/LA.norm(v)\n",
        "  return v\n",
        "\n",
        "def get_random_subspace_indexes(N, M):\n",
        "  # putting N-2 since we want maximum number as N-1\n",
        "  # taking number M-1 times since we will use last left out portion for last partition\n",
        "  split_points = np.random.choice(N - 2, M - 1, replace=False) + 1\n",
        "  split_points.sort()\n",
        "  data = np.arange(N)\n",
        "  random.shuffle(data)\n",
        "  random_subspace_indexes = np.split(data, split_points)\n",
        "  return random_subspace_indexes\n",
        "\n",
        "def make_partition(basis_matrix, N, M):\n",
        "  # given an orthonormal basis matrix, give M random subpaces which have no basis in common\n",
        "  indexes = get_random_subspace_indexes(N, M)\n",
        "  # return [(basis_matrix[i], i) for i in indexes]\n",
        "  return SubspacePartition(tuple(Subspace(basis_matrix[indice], indice) for indice in indexes))\n",
        "\n",
        "def make_random_partitions(basis_matrix, total_partitions, N):\n",
        "  mean = N//2\n",
        "  std = N/8\n",
        "  # I am using normal distribution for this, since we will have more possible number of partititons on the middle side.\n",
        "  s = np.rint(random.normal(mean, std, total_partitions))\n",
        "  \"\"\"\n",
        "  # WE CAN DO THIS TO SEE OUR DISTRIBUTION OVER HISTOGRAM\n",
        "  import matplotlib.pyplot as plt\n",
        "  num_bins = N//2\n",
        "  n, bins, patches = plt.hist(s, num_bins)\n",
        "  plt.show()\n",
        "  \"\"\"\n",
        "  for i in s:\n",
        "    if 0 < i< N:\n",
        "      yield make_partition(basis_matrix, N, M=int(i))\n",
        "\n",
        "def projected_vector(basis, vector):\n",
        "  basis = np.array(basis)\n",
        "  return LA.norm(np.matmul(np.matmul(basis, basis.T), vector))\n",
        "\n",
        "def projection(basis, vector):\n",
        "  return LA.norm(projected_vector(basis, vector))**2"
      ],
      "metadata": {
        "id": "LEoNBIT-oDPi"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PosetNode:\n",
        "    def __init__(self, value, parents, children):\n",
        "        self.value = value\n",
        "        self.children = []\n",
        "        self.parents = []\n",
        "\n",
        "class SubspacePartitionPoset:\n",
        "    def __init__(self, total_nodes=None):\n",
        "        # denotes the set of all P âˆˆ P with size k\n",
        "        self.size2partns = defaultdict(list)\n",
        "        # denotes the set of all tags inducing Partition\n",
        "        # self.partn2tags = defaultdict(list)\n",
        "        # below is equivalent to po_matrix\n",
        "        self.part2descendents = defaultdict(set) # descent is FINER\n",
        "        self.part2ancestors = defaultdict(set) # ancesteror is COARSER\n",
        "        self.part2parents = defaultdict(set)\n",
        "        self.part2children = defaultdict(set)\n",
        "        self.total_partns = 0\n",
        "        \n",
        "    def add_partitions(self, partitions, all_basis):\n",
        "      partitions.sort(key=lambda p: len(p.subspaces))\n",
        "      q = deque(partitions)\n",
        "      # iii = 0\n",
        "      LIMIT = 50\n",
        "      while q:\n",
        "        # iii+=1\n",
        "        # print(iii, end=' ')\n",
        "        P = q.popleft()\n",
        "        part_len = len(P.subspaces)\n",
        "        self.size2partns[part_len].append(P)\n",
        "        self.total_partns+=1\n",
        "        # update P.po matrix and P.hasse diagram\n",
        "        for i in range(1, part_len):\n",
        "            if self.total_partns>LIMIT:\n",
        "              print('REACHED LIMIT')\n",
        "              return\n",
        "            parts = self.size2partns[i]\n",
        "            for part in parts:\n",
        "                # size of part is less than P so P can be either finer or not coarse (it can definitely not be coarser)\n",
        "                if part.is_coarser(P) == 1:\n",
        "                    # if coarse then add entries on both nodes for ancestor and descendent\n",
        "                    self.part2descendents[part].add(P)\n",
        "                    self.part2ancestors[P].add(part)\n",
        "                join_part = SubspacePartition.join(P, part, all_basis)\n",
        "                meet_part = SubspacePartition.meet(P, part, all_basis)\n",
        "                if meet_part != P and meet_part != part:\n",
        "                    self.part2parents[P].add(meet_part)\n",
        "                    self.part2parents[part].add(meet_part)\n",
        "                    self.part2children[meet_part].add(P)\n",
        "                    self.part2children[meet_part].add(part)\n",
        "                    self.total_partns+=1\n",
        "                    q.append(meet_part)\n",
        "                if join_part != P and join_part != part:\n",
        "                    self.part2children[P].add(join_part)\n",
        "                    self.part2children[part].add(join_part)\n",
        "                    self.part2parents[join_part].add(P)\n",
        "                    self.part2parents[join_part].add(part)\n",
        "                    self.total_partns+=1\n",
        "                    q.append(join_part)"
      ],
      "metadata": {
        "id": "uS3T-KcSE34I"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_basis = get_random_bases(N)\n",
        "random_partitions = [i for i in make_random_partitions(random_basis, TOTAL_PARTITIONS, N)]\n",
        "poset = SubspacePartitionPoset()\n",
        "poset.add_partitions(random_partitions, random_basis)\n",
        "# random_partitions[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFsvTfdPh8wu",
        "outputId": "552bfc2a-7b3a-461f-e7a6-b2010e6c3607"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "REACHED LIMIT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "%#---------------------------------------------------\n",
        "%# S - basis matrix of subspace, s - energy in subspace\n",
        "%# y - vector to be projected(random initally)\n",
        "%#--------------------------------------------------\n",
        "function [Py] = projSubSphere(y, S, s);\n",
        "\tP1 = S*S'*y;\n",
        "\tP2 = y - P1;\n",
        "\tPy = s*P1/(norm(P1)+.001)+sqrt(1-s^2)*P2/(norm(P2)+.001);\n",
        "\tPy = Py/norm(Py);\n",
        "end\n",
        "%#---------------------------------------------------\n",
        "\"\"\"\n",
        "def lifting(initial_vector, basis_matrix, energy):\n",
        "  # projection of vector on subspace\n",
        "  p1 = np.matmul(np.matmul(basis_matrix, basis_matrix.T), initial_vector)\n",
        "  p2 = initial_vector - p1\n",
        "  py = energy * p1 / (LA.norm(p1) + 0.001) + (1 - energy**2)**0.5 * p2 / (LA.norm(p2) + 0.001)\n",
        "  py = py/LA.norm(py)\n",
        "  return py"
      ],
      "metadata": {
        "id": "EALsn-cnDpyG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "THIS IS MORE A TESTING RELATED CODE\n",
        "TO CHECK IF THINGS ARE IN GOOD CONDITION, SO I WILL PUT MOST OF COMMENTED CODE WHICH CAN BE USED FOR SMALL UNIT TESTING\n",
        "\"\"\"\n",
        "\n",
        "# CHECK HOW OUR RANDOM PARTITION LOOKS LIKE\n",
        "# p1 = random_partitions[0]\n",
        "# p2 = random_partitions[1]\n",
        "# for idx, i in enumerate(random_partitions):\n",
        "#   for j in random_partitions[idx:]:\n",
        "#     k = i.is_coarser(j)\n",
        "#     if k != 0:\n",
        "#       i.print_basis_idx()\n",
        "#       j.print_basis_idx()\n",
        "#       print(k, sep='  =>   ')\n",
        "\n",
        "\n",
        "# TO TEST THE IS_COARSER\n",
        "# subspaces_2 = [\n",
        "#   Subspace([np.ones(10)], [0]),\n",
        "#   Subspace([np.ones(10), np.ones(10)], [1,2]),\n",
        "#   Subspace([np.ones(10), np.ones(10)], [3,4]),\n",
        "#   Subspace([np.ones(10), np.ones(10)], [5,6]),\n",
        "#   Subspace([np.ones(10), np.ones(10)], [7,8]),\n",
        "#   Subspace([np.ones(10), np.ones(10)], [9]),\n",
        "# ]\n",
        "# subspaces_1 = [\n",
        "#   Subspace([np.ones(10)], [0,1,2,3,4,5,6]),\n",
        "#   Subspace([np.ones(10)], [7,8, 9]),\n",
        "# ]\n",
        "# p1 = SubspacePartition(subspaces_2)\n",
        "# p2 = SubspacePartition(subspaces_1)\n",
        "# p1.print_basis_idx()\n",
        "# p2.print_basis_idx()\n",
        "# print(p1.is_coarser(p2))\n",
        "\n",
        "\n",
        "# CHECK JOIN AND MEET\n",
        "# random_partitions[0].print_basis_idx(), random_partitions[1].print_basis_idx()\n",
        "# p = SubspacePartition.join(random_partitions[0], random_partitions[1], random_basis)\n",
        "# p.print_basis_idx()\n",
        "# p.print_partition()"
      ],
      "metadata": {
        "id": "a1IzxntgIGj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pq9l9s-TuEcf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}