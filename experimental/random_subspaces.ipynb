{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "random_subspaces.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMjPPWpNuDxg4DjyDjZfivn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OculusMode/ILL/blob/main/experimental/random_subspaces.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LAmaSrnePaXk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numpy import random, linalg as LA\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TOTAL_VECTORS = 64\n",
        "VECTOR_SIZE = 8\n",
        "# random.seed(45)\n",
        "random_vectors = random.rand(TOTAL_VECTORS, VECTOR_SIZE)"
      ],
      "metadata": {
        "id": "54jqqVnGPck7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_random_decomposition(random_vectors):\n",
        "  # finding 8 random indices from 64 to choose random vectors\n",
        "  # random.seed(42)\n",
        "  random_indices = random.choice(TOTAL_VECTORS, size = VECTOR_SIZE)\n",
        "  while True:\n",
        "    random_chosen_vectors = random_vectors[random_indices]\n",
        "    random_basis, _ = LA.qr(random_chosen_vectors)\n",
        "    # making sure we got 8 basis\n",
        "    if LA.matrix_rank(random_basis) == VECTOR_SIZE:\n",
        "      break\n",
        "  # number of subspaces to choose\n",
        "  # random.seed(15)\n",
        "  total_splits = random.randint(2, VECTOR_SIZE)\n",
        "  # split points to split array\n",
        "  # random.seed(10)\n",
        "  split_points = np.random.choice(VECTOR_SIZE - 2, total_splits - 1, replace = False) + 1\n",
        "  split_points.sort()\n",
        "  return np.split(random_basis, split_points)\n",
        "\n",
        "\n",
        "def projected_vector(basis, vector):\n",
        "  # our basis vector here is row vector so (1, 10) => we want something like (10,1)\n",
        "  return np.matmul(basis.T, vector)\n",
        "\n",
        "def projection(basis, vector):\n",
        "  return LA.norm(projected_vector(basis, vector))\n",
        "\n",
        "def lifting(initial_vector, basis_matrix, energy):\n",
        "# projection of vector on subspace\n",
        "  p1 = np.matmul(np.matmul(basis_matrix.T, basis_matrix), initial_vector)\n",
        "  p2 = initial_vector - p1\n",
        "  py = energy * p1 / (LA.norm(p1) + 0.001) + (1 - energy**2)**0.5 * p2 / (LA.norm(p2) + 0.001)\n",
        "  py = py/LA.norm(py)\n",
        "  return py"
      ],
      "metadata": {
        "id": "QXQj8I00Pgof"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_test(epoch=10, no_decompositions=50):\n",
        "  decompositions = []\n",
        "  for i in range(no_decompositions):\n",
        "    decompositions.append(get_random_decomposition(random_vectors))\n",
        "  signal = random.rand(VECTOR_SIZE)\n",
        "  signal = signal/LA.norm(signal)\n",
        "  energies = []\n",
        "  for decomposition in decompositions:\n",
        "    e = []\n",
        "    for subspace in decomposition:\n",
        "      e.append(projection(subspace.T, signal))\n",
        "    energies.append(e)\n",
        "  random_vector = random.rand(VECTOR_SIZE)\n",
        "  random_vector = random_vector/LA.norm(random_vector)\n",
        "  for i in range(epoch):\n",
        "    x = np.arange(no_decompositions)\n",
        "    for idx_decomp, d in enumerate(decompositions):\n",
        "      for idx_ss, subspace in enumerate(d):\n",
        "        # print(subspace.shape, signal.shape)\n",
        "        random_vector = lifting(random_vector, subspace, energies[idx_decomp][idx_ss])\n",
        "  # print(LA.norm(random_vector - signal))\n",
        "  if LA.norm(random_vector - signal) < 0.05:\n",
        "    return 1\n",
        "  return 0\n"
      ],
      "metadata": {
        "id": "iQMRax1qgvp_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decomps = range(10, 60, 10)\n",
        "\n",
        "tot = 1000\n",
        "for d_no in decomps:\n",
        "  tot_p = []\n",
        "  for _ in range(5):\n",
        "    # to have fixed output\n",
        "    # random.seed(42)\n",
        "    tot_succ=0\n",
        "    for i in range(tot):\n",
        "      tot_succ+=run_test(no_decompositions=d_no)\n",
        "    # print(tot, tot_succ/tot)\n",
        "    tot_p.append(tot_succ/tot)\n",
        "  print(tot_p)\n",
        "# 28 min\n",
        "\n",
        "\"\"\"\n",
        "DO IT FOR 100/1000 times\n",
        "AND FOR INCREMENTING NUMBER OF decompositions\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "TdzEdiKS3WZ4",
        "outputId": "85b08e61-baff-4840-ea98-425a82812a6c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.978, 0.978, 0.987, 0.983, 0.992]\n",
            "[0.985, 0.992, 0.987, 0.985, 0.982]\n",
            "[0.989, 0.986, 0.99, 0.991, 0.982]\n",
            "[0.991, 0.984, 0.987, 0.982, 0.987]\n",
            "[0.983, 0.989, 0.985, 0.983, 0.992]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nDO IT FOR 100/1000 times\\nAND FOR INCREMENTING NUMBER OF decompositions\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = [\n",
        "  [0.978, 0.978, 0.987, 0.983, 0.992], # \n",
        "  [0.985, 0.992, 0.987, 0.985, 0.982], # \n",
        "  [0.989, 0.986, 0.99, 0.991, 0.982], # \n",
        "  [0.991, 0.984, 0.987, 0.982, 0.987], # \n",
        "  [0.983, 0.989, 0.985, 0.983, 0.992], # \n",
        "]\n",
        "[sum(i)/5 for i in res]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ksux0i0dhhRw",
        "outputId": "193d7abc-572d-41b2-bdaf-886986056d77"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9836, 0.9862, 0.9875999999999999, 0.9862, 0.9864]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# totally random\n",
        "def get_random_energy(vector_size, random_signal):\n",
        "  subspace_size = random.randint(1, vector_size + 1)\n",
        "  while True:\n",
        "    a = random.rand(vector_size, subspace_size)\n",
        "    basis, _ = LA.qr(a)\n",
        "    if LA.matrix_rank(basis) == subspace_size:\n",
        "      break\n",
        "  # print(projection(q, random_signal))\n",
        "  return projection(basis, random_signal)\n",
        "  \n",
        "# so we will create hella data. honestly, basically 50 energies for each signal.\n",
        "def get_data(vector_size, no_of_rows, no_of_columns):\n",
        "  \n",
        "  # starting with creating bunch of subspaces (no_of_columns)\n",
        "  random_vectors = random.rand(256, vector_size)\n",
        "  subspaces_basis = []\n",
        "\n",
        "  # adding N number of subspaces in a list(then we can count energy for random signals)\n",
        "  for row in range(no_of_columns):\n",
        "    subspace_size = random.randint(1, vector_size + 1)\n",
        "    random_indices = random.choice(256, size = subspace_size)\n",
        "    while True:\n",
        "      a = random_vectors[random_indices].T\n",
        "      basis, _ = LA.qr(a)\n",
        "      if LA.matrix_rank(basis) == subspace_size:\n",
        "        break\n",
        "    subspaces_basis.append(basis)\n",
        "  \n",
        "  Y = []\n",
        "  X = []\n",
        "  for _ in range(no_of_rows):\n",
        "    random_signal = random.rand(vector_size)\n",
        "    random_signal = random_signal/np.sum(random_signal)\n",
        "    Y.append(random_signal)\n",
        "    X.append([projection(basis, random_signal) for basis in subspaces_basis])\n",
        "  X = np.array(X)\n",
        "  return X, np.array(Y)\n",
        "X, Y = get_data(8, 10_000, 50)"
      ],
      "metadata": {
        "id": "o7-S0BQT5hLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import loadtxt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras import metrics\n",
        "import tensorflow as tf\n",
        "\n",
        "X_train = X[:7000]\n",
        "X_test = X[7000:]\n",
        "y_train = Y[:7000]\n",
        "y_test = Y[7000:]\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
        "model = Sequential()\n",
        "model.add(Dense(50, input_dim=50, activation='relu'))\n",
        "# model.add(Dropout(0.2))\n",
        "# model.add(Dense(32, activation='relu'))\n",
        "# model.add(Dropout(0.2))\n",
        "# model.add(Dense(16, activation='relu'))\n",
        "# model.add(Dropout(0.2))\n",
        "model.add(Dense(8, activation='sigmoid'))\n",
        "# compile the keras model\n",
        "# def my_metric_fn(y_true, y_pred):\n",
        "#   print('=>',y_true.shape, y_pred.shape)\n",
        "#   return tf.norm(y_true - y_pred)\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam', \n",
        "    loss='mean_squared_error',\n",
        "    metrics=[\n",
        "        'accuracy',\n",
        "        'mean_squared_error'\n",
        "    ])\n",
        "# fit the keras model on the dataset\n",
        "# , verbose=0\n",
        "history = model.fit(X_train, y_train, epochs=150, batch_size=8)\n",
        "# evaluate the keras model\n",
        "_, a, b = model.evaluate(X_test, y_test)\n",
        "# print('Accuracy: %.2f' % (mse*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bj3Vv64whF0a",
        "outputId": "dad8f734-32f8-4551-eb15-4943e1f19eb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7000, 50) (3000, 50) (7000, 8) (3000, 8)\n",
            "Epoch 1/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 0.0077 - accuracy: 0.1907 - mean_squared_error: 0.0077\n",
            "Epoch 2/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 0.0045 - accuracy: 0.3330 - mean_squared_error: 0.0045\n",
            "Epoch 3/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 0.0036 - accuracy: 0.3869 - mean_squared_error: 0.0036\n",
            "Epoch 4/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 0.0029 - accuracy: 0.4529 - mean_squared_error: 0.0029\n",
            "Epoch 5/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 0.0023 - accuracy: 0.5169 - mean_squared_error: 0.0023\n",
            "Epoch 6/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 0.0018 - accuracy: 0.5614 - mean_squared_error: 0.0018\n",
            "Epoch 7/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 0.0014 - accuracy: 0.6183 - mean_squared_error: 0.0014\n",
            "Epoch 8/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 0.0011 - accuracy: 0.6656 - mean_squared_error: 0.0011\n",
            "Epoch 9/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 8.4333e-04 - accuracy: 0.7110 - mean_squared_error: 8.4333e-04\n",
            "Epoch 10/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 6.8197e-04 - accuracy: 0.7500 - mean_squared_error: 6.8197e-04\n",
            "Epoch 11/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 5.8209e-04 - accuracy: 0.7707 - mean_squared_error: 5.8209e-04\n",
            "Epoch 12/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 5.1878e-04 - accuracy: 0.7871 - mean_squared_error: 5.1878e-04\n",
            "Epoch 13/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 4.8275e-04 - accuracy: 0.7977 - mean_squared_error: 4.8275e-04\n",
            "Epoch 14/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 4.5867e-04 - accuracy: 0.8037 - mean_squared_error: 4.5867e-04\n",
            "Epoch 15/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 4.4498e-04 - accuracy: 0.8043 - mean_squared_error: 4.4498e-04\n",
            "Epoch 16/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 4.2399e-04 - accuracy: 0.8099 - mean_squared_error: 4.2399e-04\n",
            "Epoch 17/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 4.0863e-04 - accuracy: 0.8134 - mean_squared_error: 4.0863e-04\n",
            "Epoch 18/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 4.0043e-04 - accuracy: 0.8151 - mean_squared_error: 4.0043e-04\n",
            "Epoch 19/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 3.8474e-04 - accuracy: 0.8209 - mean_squared_error: 3.8474e-04\n",
            "Epoch 20/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 3.7858e-04 - accuracy: 0.8236 - mean_squared_error: 3.7858e-04\n",
            "Epoch 21/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 3.6408e-04 - accuracy: 0.8233 - mean_squared_error: 3.6408e-04\n",
            "Epoch 22/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 3.5358e-04 - accuracy: 0.8301 - mean_squared_error: 3.5358e-04\n",
            "Epoch 23/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 3.4804e-04 - accuracy: 0.8280 - mean_squared_error: 3.4804e-04\n",
            "Epoch 24/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 3.3569e-04 - accuracy: 0.8330 - mean_squared_error: 3.3569e-04\n",
            "Epoch 25/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 3.3411e-04 - accuracy: 0.8217 - mean_squared_error: 3.3411e-04\n",
            "Epoch 26/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 3.2328e-04 - accuracy: 0.8377 - mean_squared_error: 3.2328e-04\n",
            "Epoch 27/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 3.1793e-04 - accuracy: 0.8327 - mean_squared_error: 3.1793e-04\n",
            "Epoch 28/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 3.1104e-04 - accuracy: 0.8361 - mean_squared_error: 3.1104e-04\n",
            "Epoch 29/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 3.0003e-04 - accuracy: 0.8389 - mean_squared_error: 3.0003e-04\n",
            "Epoch 30/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 2.9817e-04 - accuracy: 0.8414 - mean_squared_error: 2.9817e-04\n",
            "Epoch 31/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 2.9223e-04 - accuracy: 0.8339 - mean_squared_error: 2.9223e-04\n",
            "Epoch 32/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 2.8676e-04 - accuracy: 0.8431 - mean_squared_error: 2.8676e-04\n",
            "Epoch 33/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 2.8051e-04 - accuracy: 0.8427 - mean_squared_error: 2.8051e-04\n",
            "Epoch 34/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 2.7648e-04 - accuracy: 0.8407 - mean_squared_error: 2.7648e-04\n",
            "Epoch 35/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 2.7200e-04 - accuracy: 0.8424 - mean_squared_error: 2.7200e-04\n",
            "Epoch 36/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 2.6315e-04 - accuracy: 0.8476 - mean_squared_error: 2.6315e-04\n",
            "Epoch 37/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 2.6111e-04 - accuracy: 0.8439 - mean_squared_error: 2.6111e-04\n",
            "Epoch 38/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 2.5657e-04 - accuracy: 0.8439 - mean_squared_error: 2.5657e-04\n",
            "Epoch 39/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 2.4995e-04 - accuracy: 0.8409 - mean_squared_error: 2.4995e-04\n",
            "Epoch 40/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 2.4728e-04 - accuracy: 0.8463 - mean_squared_error: 2.4728e-04\n",
            "Epoch 41/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 2.4178e-04 - accuracy: 0.8479 - mean_squared_error: 2.4178e-04\n",
            "Epoch 42/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 2.3943e-04 - accuracy: 0.8480 - mean_squared_error: 2.3943e-04\n",
            "Epoch 43/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 2.3570e-04 - accuracy: 0.8441 - mean_squared_error: 2.3570e-04\n",
            "Epoch 44/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 2.3094e-04 - accuracy: 0.8457 - mean_squared_error: 2.3094e-04\n",
            "Epoch 45/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 2.2405e-04 - accuracy: 0.8526 - mean_squared_error: 2.2405e-04\n",
            "Epoch 46/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 2.2231e-04 - accuracy: 0.8524 - mean_squared_error: 2.2231e-04\n",
            "Epoch 47/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 2.1912e-04 - accuracy: 0.8496 - mean_squared_error: 2.1912e-04\n",
            "Epoch 48/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 2.1814e-04 - accuracy: 0.8457 - mean_squared_error: 2.1814e-04\n",
            "Epoch 49/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 2.1316e-04 - accuracy: 0.8481 - mean_squared_error: 2.1316e-04\n",
            "Epoch 50/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 2.0941e-04 - accuracy: 0.8486 - mean_squared_error: 2.0941e-04\n",
            "Epoch 51/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 2.1417e-04 - accuracy: 0.8414 - mean_squared_error: 2.1417e-04\n",
            "Epoch 52/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 2.0203e-04 - accuracy: 0.8490 - mean_squared_error: 2.0203e-04\n",
            "Epoch 53/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 2.0352e-04 - accuracy: 0.8510 - mean_squared_error: 2.0352e-04\n",
            "Epoch 54/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.9858e-04 - accuracy: 0.8494 - mean_squared_error: 1.9858e-04\n",
            "Epoch 55/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.9657e-04 - accuracy: 0.8571 - mean_squared_error: 1.9657e-04\n",
            "Epoch 56/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.9450e-04 - accuracy: 0.8540 - mean_squared_error: 1.9450e-04\n",
            "Epoch 57/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.9093e-04 - accuracy: 0.8566 - mean_squared_error: 1.9093e-04\n",
            "Epoch 58/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.8881e-04 - accuracy: 0.8573 - mean_squared_error: 1.8881e-04\n",
            "Epoch 59/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.8606e-04 - accuracy: 0.8573 - mean_squared_error: 1.8606e-04\n",
            "Epoch 60/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.8532e-04 - accuracy: 0.8479 - mean_squared_error: 1.8532e-04\n",
            "Epoch 61/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.8306e-04 - accuracy: 0.8567 - mean_squared_error: 1.8306e-04\n",
            "Epoch 62/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.8005e-04 - accuracy: 0.8561 - mean_squared_error: 1.8005e-04\n",
            "Epoch 63/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.7727e-04 - accuracy: 0.8496 - mean_squared_error: 1.7727e-04\n",
            "Epoch 64/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.7632e-04 - accuracy: 0.8597 - mean_squared_error: 1.7632e-04\n",
            "Epoch 65/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.7208e-04 - accuracy: 0.8673 - mean_squared_error: 1.7208e-04\n",
            "Epoch 66/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.7088e-04 - accuracy: 0.8610 - mean_squared_error: 1.7088e-04\n",
            "Epoch 67/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.7047e-04 - accuracy: 0.8611 - mean_squared_error: 1.7047e-04\n",
            "Epoch 68/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.6684e-04 - accuracy: 0.8650 - mean_squared_error: 1.6684e-04\n",
            "Epoch 69/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.6716e-04 - accuracy: 0.8619 - mean_squared_error: 1.6716e-04\n",
            "Epoch 70/150\n",
            "875/875 [==============================] - 2s 3ms/step - loss: 1.6431e-04 - accuracy: 0.8596 - mean_squared_error: 1.6431e-04\n",
            "Epoch 71/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.6506e-04 - accuracy: 0.8576 - mean_squared_error: 1.6506e-04\n",
            "Epoch 72/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.5876e-04 - accuracy: 0.8639 - mean_squared_error: 1.5876e-04\n",
            "Epoch 73/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.6163e-04 - accuracy: 0.8583 - mean_squared_error: 1.6163e-04\n",
            "Epoch 74/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.5817e-04 - accuracy: 0.8594 - mean_squared_error: 1.5817e-04\n",
            "Epoch 75/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.5875e-04 - accuracy: 0.8629 - mean_squared_error: 1.5875e-04\n",
            "Epoch 76/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.5445e-04 - accuracy: 0.8641 - mean_squared_error: 1.5445e-04\n",
            "Epoch 77/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.5422e-04 - accuracy: 0.8616 - mean_squared_error: 1.5422e-04\n",
            "Epoch 78/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.5196e-04 - accuracy: 0.8687 - mean_squared_error: 1.5196e-04\n",
            "Epoch 79/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.5331e-04 - accuracy: 0.8634 - mean_squared_error: 1.5331e-04\n",
            "Epoch 80/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.5273e-04 - accuracy: 0.8627 - mean_squared_error: 1.5273e-04\n",
            "Epoch 81/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.5030e-04 - accuracy: 0.8601 - mean_squared_error: 1.5030e-04\n",
            "Epoch 82/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.4847e-04 - accuracy: 0.8629 - mean_squared_error: 1.4847e-04\n",
            "Epoch 83/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.4903e-04 - accuracy: 0.8654 - mean_squared_error: 1.4903e-04\n",
            "Epoch 84/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.4740e-04 - accuracy: 0.8586 - mean_squared_error: 1.4740e-04\n",
            "Epoch 85/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.4797e-04 - accuracy: 0.8634 - mean_squared_error: 1.4797e-04\n",
            "Epoch 86/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.4462e-04 - accuracy: 0.8680 - mean_squared_error: 1.4462e-04\n",
            "Epoch 87/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.4452e-04 - accuracy: 0.8626 - mean_squared_error: 1.4452e-04\n",
            "Epoch 88/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.4252e-04 - accuracy: 0.8700 - mean_squared_error: 1.4252e-04\n",
            "Epoch 89/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.4235e-04 - accuracy: 0.8677 - mean_squared_error: 1.4235e-04\n",
            "Epoch 90/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.4064e-04 - accuracy: 0.8603 - mean_squared_error: 1.4064e-04\n",
            "Epoch 91/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.4114e-04 - accuracy: 0.8654 - mean_squared_error: 1.4114e-04\n",
            "Epoch 92/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.3983e-04 - accuracy: 0.8679 - mean_squared_error: 1.3983e-04\n",
            "Epoch 93/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.4304e-04 - accuracy: 0.8599 - mean_squared_error: 1.4304e-04\n",
            "Epoch 94/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.3665e-04 - accuracy: 0.8670 - mean_squared_error: 1.3665e-04\n",
            "Epoch 95/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.3525e-04 - accuracy: 0.8739 - mean_squared_error: 1.3525e-04\n",
            "Epoch 96/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.3650e-04 - accuracy: 0.8623 - mean_squared_error: 1.3650e-04\n",
            "Epoch 97/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.3563e-04 - accuracy: 0.8654 - mean_squared_error: 1.3563e-04\n",
            "Epoch 98/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.3623e-04 - accuracy: 0.8639 - mean_squared_error: 1.3623e-04\n",
            "Epoch 99/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.3544e-04 - accuracy: 0.8686 - mean_squared_error: 1.3544e-04\n",
            "Epoch 100/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.3166e-04 - accuracy: 0.8676 - mean_squared_error: 1.3166e-04\n",
            "Epoch 101/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.3133e-04 - accuracy: 0.8664 - mean_squared_error: 1.3133e-04\n",
            "Epoch 102/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.3391e-04 - accuracy: 0.8686 - mean_squared_error: 1.3391e-04\n",
            "Epoch 103/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.3054e-04 - accuracy: 0.8719 - mean_squared_error: 1.3054e-04\n",
            "Epoch 104/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.3138e-04 - accuracy: 0.8690 - mean_squared_error: 1.3138e-04\n",
            "Epoch 105/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.3051e-04 - accuracy: 0.8689 - mean_squared_error: 1.3051e-04\n",
            "Epoch 106/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.2870e-04 - accuracy: 0.8727 - mean_squared_error: 1.2870e-04\n",
            "Epoch 107/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.2774e-04 - accuracy: 0.8717 - mean_squared_error: 1.2774e-04\n",
            "Epoch 108/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.2806e-04 - accuracy: 0.8723 - mean_squared_error: 1.2806e-04\n",
            "Epoch 109/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.2908e-04 - accuracy: 0.8699 - mean_squared_error: 1.2908e-04\n",
            "Epoch 110/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.2725e-04 - accuracy: 0.8720 - mean_squared_error: 1.2725e-04\n",
            "Epoch 111/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.2612e-04 - accuracy: 0.8717 - mean_squared_error: 1.2612e-04\n",
            "Epoch 112/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.2543e-04 - accuracy: 0.8704 - mean_squared_error: 1.2543e-04\n",
            "Epoch 113/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.2613e-04 - accuracy: 0.8691 - mean_squared_error: 1.2613e-04\n",
            "Epoch 114/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.2525e-04 - accuracy: 0.8646 - mean_squared_error: 1.2525e-04\n",
            "Epoch 115/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.2317e-04 - accuracy: 0.8716 - mean_squared_error: 1.2317e-04\n",
            "Epoch 116/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.2285e-04 - accuracy: 0.8730 - mean_squared_error: 1.2285e-04\n",
            "Epoch 117/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.2198e-04 - accuracy: 0.8706 - mean_squared_error: 1.2198e-04\n",
            "Epoch 118/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.2156e-04 - accuracy: 0.8703 - mean_squared_error: 1.2156e-04\n",
            "Epoch 119/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.2150e-04 - accuracy: 0.8681 - mean_squared_error: 1.2150e-04\n",
            "Epoch 120/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.2172e-04 - accuracy: 0.8729 - mean_squared_error: 1.2172e-04\n",
            "Epoch 121/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.2056e-04 - accuracy: 0.8710 - mean_squared_error: 1.2056e-04\n",
            "Epoch 122/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.1887e-04 - accuracy: 0.8747 - mean_squared_error: 1.1887e-04\n",
            "Epoch 123/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.1970e-04 - accuracy: 0.8684 - mean_squared_error: 1.1970e-04\n",
            "Epoch 124/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.1995e-04 - accuracy: 0.8673 - mean_squared_error: 1.1995e-04\n",
            "Epoch 125/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.1814e-04 - accuracy: 0.8721 - mean_squared_error: 1.1814e-04\n",
            "Epoch 126/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.1797e-04 - accuracy: 0.8747 - mean_squared_error: 1.1797e-04\n",
            "Epoch 127/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.1645e-04 - accuracy: 0.8733 - mean_squared_error: 1.1645e-04\n",
            "Epoch 128/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.1337e-04 - accuracy: 0.8770 - mean_squared_error: 1.1337e-04\n",
            "Epoch 129/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.1761e-04 - accuracy: 0.8654 - mean_squared_error: 1.1761e-04\n",
            "Epoch 130/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.1237e-04 - accuracy: 0.8806 - mean_squared_error: 1.1237e-04\n",
            "Epoch 131/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.1304e-04 - accuracy: 0.8701 - mean_squared_error: 1.1304e-04\n",
            "Epoch 132/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.1340e-04 - accuracy: 0.8740 - mean_squared_error: 1.1340e-04\n",
            "Epoch 133/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.1081e-04 - accuracy: 0.8719 - mean_squared_error: 1.1081e-04\n",
            "Epoch 134/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.0836e-04 - accuracy: 0.8760 - mean_squared_error: 1.0836e-04\n",
            "Epoch 135/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.0689e-04 - accuracy: 0.8779 - mean_squared_error: 1.0689e-04\n",
            "Epoch 136/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.0703e-04 - accuracy: 0.8764 - mean_squared_error: 1.0703e-04\n",
            "Epoch 137/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.0870e-04 - accuracy: 0.8724 - mean_squared_error: 1.0870e-04\n",
            "Epoch 138/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.0727e-04 - accuracy: 0.8727 - mean_squared_error: 1.0727e-04\n",
            "Epoch 139/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.0697e-04 - accuracy: 0.8704 - mean_squared_error: 1.0697e-04\n",
            "Epoch 140/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.0503e-04 - accuracy: 0.8764 - mean_squared_error: 1.0503e-04\n",
            "Epoch 141/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.0461e-04 - accuracy: 0.8803 - mean_squared_error: 1.0461e-04\n",
            "Epoch 142/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.0516e-04 - accuracy: 0.8740 - mean_squared_error: 1.0516e-04\n",
            "Epoch 143/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.0500e-04 - accuracy: 0.8717 - mean_squared_error: 1.0500e-04\n",
            "Epoch 144/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.0442e-04 - accuracy: 0.8786 - mean_squared_error: 1.0442e-04\n",
            "Epoch 145/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.0230e-04 - accuracy: 0.8820 - mean_squared_error: 1.0230e-04\n",
            "Epoch 146/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.0115e-04 - accuracy: 0.8739 - mean_squared_error: 1.0115e-04\n",
            "Epoch 147/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.0081e-04 - accuracy: 0.8767 - mean_squared_error: 1.0081e-04\n",
            "Epoch 148/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.0054e-04 - accuracy: 0.8734 - mean_squared_error: 1.0054e-04\n",
            "Epoch 149/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 1.0149e-04 - accuracy: 0.8756 - mean_squared_error: 1.0149e-04\n",
            "Epoch 150/150\n",
            "875/875 [==============================] - 2s 2ms/step - loss: 9.9587e-05 - accuracy: 0.8796 - mean_squared_error: 9.9587e-05\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 1.0173e-04 - accuracy: 0.8713 - mean_squared_error: 1.0173e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avg = 0\n",
        "for i in range(7001, 10_000):\n",
        "  avg += np.sum(np.abs(model.predict(X[i].reshape(1, 50)) - Y[i]))\n",
        "# print('Accuracy: %.2f' % (mse*100))\n",
        "print(avg/3000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnooQ0-W5nKu",
        "outputId": "dc65c8c0-b282-4b7c-e044-7d7381ded616"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.059595319544573054\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(X[8000].reshape(1, 50)), Y[8000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0LbnMp81qKk",
        "outputId": "b8507640-a38b-4b6a-e62d-4b94a75ddd63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0.06986117, 0.14935306, 0.08382797, 0.23959151, 0.04598585,\n",
              "         0.06464773, 0.13845652, 0.20590544]], dtype=float32),\n",
              " array([0.0667871 , 0.15769052, 0.08787615, 0.23726378, 0.03377103,\n",
              "        0.06671555, 0.13498634, 0.21490952]))"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22L_OAfitlht",
        "outputId": "84708ad4-7234-4e88-db78-5c9eb69bdeab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7261c41cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    }
  ]
}